name: Build and Deploy

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:  # Allows manual triggering

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: django-microservice
  EKS_CLUSTER_NAME: django-microservice-cluster  # Updated to match your actual cluster name

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1

    - name: Build, tag, and push image to Amazon ECR
      id: build-image
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        # Build a docker container and push it to ECR
        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
        
        # Also tag as latest
        docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
        
        echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT
    
    - name: Install kubectl
      uses: azure/setup-kubectl@v3
      
    - name: Update kubeconfig
      run: aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER_NAME }}
    
    - name: Process Kubernetes manifests
      run: |
        export ECR_REPO_URL=${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}
        
        # Process the manifest file to replace variables
        cat microservices-k8.yml | \
        sed "s|\${ECR_REPO_URL}|$ECR_REPO_URL|g" > microservices-k8-processed.yml
        
    - name: Deploy core infrastructure
      run: |
        # Apply everything except the migration job first
        grep -v "name: django-migrate" microservices-k8-processed.yml > core-infrastructure.yml
        kubectl apply -f core-infrastructure.yml
        
        # Check if database pod is created
        echo "Waiting for database pod to be created..."
        kubectl get pods -l app=postgres --no-headers || true
        
        # Wait for database to be ready with longer timeout
        echo "Waiting for database to be ready..."
        kubectl wait --for=condition=available --timeout=600s deployment/postgres || true
        
        # Verify postgres pod is running
        echo "Postgres pod status:"
        kubectl get pods -l app=postgres -o wide
        
        # Give the database more time to initialize
        echo "Giving database time to initialize..."
        sleep 60
    
    - name: Run database migrations
      run: |
        # Generate a unique job name with commit hash
        COMMIT_HASH=$(echo ${{ github.sha }} | cut -c1-40)
        JOB_NAME="django-migrate-$COMMIT_HASH"
        
        # Extract the migration job and add a unique name
        cat microservices-k8-processed.yml | \
          sed -n '/# Django Migrate Job/,/---/p' | \
          sed "s/name: django-migrate/name: $JOB_NAME/" > migration-job.yml
        
        echo "Creating migration job..."
        kubectl apply -f migration-job.yml
        
        echo "Waiting for migrations to complete..."
        
        # Wait with increased timeout
        if ! kubectl wait --for=condition=complete --timeout=300s job/$JOB_NAME; then
          echo "Migration job didn't complete in the allowed time, checking logs and status..."
          
          # Get migration pod name
          POD_NAME=$(kubectl get pods -l job-name=$JOB_NAME -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
          
          if [ -n "$POD_NAME" ]; then
            echo "Migration pod status:"
            kubectl describe pod $POD_NAME || true
            
            # Check init container status
            echo "Init container status:"
            kubectl get pod $POD_NAME -o jsonpath='{.status.initContainerStatuses[*].name}' || true
            
            echo "Init container logs (database readiness check):"
            kubectl logs $POD_NAME -c check-db-ready || true
            
            echo "Migration logs (if container has started):"
            kubectl logs $POD_NAME -c django || true
            
            # Check for common issues with PostgreSQL
            echo "PostgreSQL service status:"
            kubectl get svc db || true
            
            echo "PostgreSQL pod logs:"
            kubectl logs $(kubectl get pods -l app=postgres -o jsonpath='{.items[0].metadata.name}') || true
          else
            echo "Migration pod not found!"
          fi
          
          # Check if job is still running and give it more time
          if kubectl get job $JOB_NAME -o jsonpath='{.status.active}' 2>/dev/null | grep -q 1; then
            echo "Job is still running, giving it more time (120s)..."
            sleep 120
            kubectl wait --for=condition=complete --timeout=120s job/$JOB_NAME || true
            
            POD_NAME=$(kubectl get pods -l job-name=$JOB_NAME -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
            if [ -n "$POD_NAME" ]; then
              echo "Final migration logs:"
              kubectl logs $POD_NAME -c django || true
            fi
          fi
          
          # Final status check
          JOB_SUCCEEDED=$(kubectl get job $JOB_NAME -o jsonpath='{.status.succeeded}' 2>/dev/null)
          if [ "$JOB_SUCCEEDED" == "1" ]; then
            echo "Migration job eventually succeeded"
          else
            echo "Migration job failed or is still pending"
            echo "Manual intervention may be required"
            # Continue deployment anyway - this might be an issue with the migration job rather than migrations
            echo "Continuing with deployment despite migration issues"
          fi
        else
          echo "Migrations completed successfully!"
        fi
    
    - name: Restart deployments
      run: |
        kubectl rollout restart deployment web
        kubectl rollout restart deployment worker
        kubectl rollout status deployment web --timeout=180s
        kubectl rollout status deployment worker --timeout=180s
    
    - name: Get service URL
      run: |
        echo "Application deployed successfully!"
        LOAD_BALANCER=$(kubectl get svc -o jsonpath='{.items[?(@.spec.type=="LoadBalancer")].status.loadBalancer.ingress[0].hostname}')
        if [ -n "$LOAD_BALANCER" ]; then
          echo "Application is available at: http://$LOAD_BALANCER/"
        else
          echo "No LoadBalancer found."
        fi